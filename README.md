# GCP-POC-DataPipeline
> Using **Composer**, migrate the data from AWS S3 or Azure Blob Storage to Google Cloud Storage and then move to datastore

> Using **Pubsub** for passing Barcode (Fact data)

> Using **Datastore** for Product Catalog (Product Dimentions)

> Using **Dataflow**, join data between Pubsub (streaming) and Cloud Datastore (Static Data) and do some transformation and load into Bigquery

> Use **BigQuery** for data warehouse
